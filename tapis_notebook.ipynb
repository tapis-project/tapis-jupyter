{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tapis PEARC20 Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use Tapis to store and analyze streaming data generated from code simulating a sensor. We introduce a number of Tapis services and concepts along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/Tapisworkflow.png \"a title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tapis Python SDK, Tenants and Authentication\n",
    "\n",
    "In this notebook, we will use the official Tapis Python SDK for all of our interactions with the services. The Python SDK provides Python-native methods and objects for making HTTP requests and parsing HTTP responses to and from the Tapis API. \n",
    "\n",
    "In order to do just about anything with Tapis, we will need to authenticate. Tapis makes heavy use of the notion of \"tenants\" in order to provide isolation for different projects. By setting the base_url variable, you indicate to the Tapis SDK which tenant you wish to interact with.\n",
    "\n",
    "For the demo, we will be using a base_url of \"https://tacc.tapis.io\" -- the \"TACC tenant\" -- which will allow us to authenticate using any valid TACC account. For other tenants, the authentication rules could be different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication in the TACC tenant uses OAuth2 (again, this could be different in other tenants), but the Tapis Python SDK simplifies some of the complexity inherent in OAuth2 by providing some convenience functions for common use cases. For example, we are able to generate an access token using just our username and password via the convenience function “get_tokens()”. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import getpass\n",
    "import os\n",
    "#Setup Variables that are used in the rest of the notebook\n",
    "permitted_username = getpass.getpass(prompt='Permitted Username: ', stream=None)\n",
    "permitted_user_password = getpass.getpass(prompt='Permitted Password: ', stream=None)\n",
    "non_permitted_username = getpass.getpass(prompt='Non Permitted Username: ', stream=None)\n",
    "non_permitted_password = getpass.getpass(prompt='Non Permitted Password: ', stream=None)\n",
    "tenant=\"dev\"\n",
    "base_url = 'https://dev.tapis.io'\n",
    "\n",
    "#update project id so the rest can create in as unique objects\n",
    "project_id ='wq_demo_tapis_proj1'+ str(datetime.datetime.today().isoformat())\n",
    "\n",
    "site_id = 'wq_demo_site'\n",
    "instrument_id = 'Ohio_River_Robert_C_Byrd_Locks'\n",
    "channel_id = 'demo_wq_channel'+  str(datetime.datetime.today().isoformat()).replace(':','_')\n",
    "template_id = 'demo_channel_template'\n",
    "nonce = os.environ['ABACO_NONCE']\n",
    "actor_id = \"Aw1ebg4GG1JrO\"\n",
    "storage_id = \"tapis-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Python SDK\n",
    "from tapy.dyna import DynaTapy \n",
    "\n",
    "#Create python Tapis client for user\n",
    "permitted_client = DynaTapy(base_url= base_url, username=permitted_username, password=permitted_user_password, account_type='user', tenant_id='dev') \n",
    "permitted_client.get_tokens()\n",
    "\n",
    "#Create python Tapis client for non-permitted user\n",
    "nonpermitted_client = DynaTapy(base_url= base_url, username=non_permitted_username, password=non_permitted_password, account_type='user', tenant_id='dev') \n",
    "nonpermitted_client.get_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tapis, access tokens (and refresh tokens) are simply JSON Web Tokens (JWTs). The access_token Python object created and managed by the Python SDK has attributes on it that include the \"raw\" JWT string as well as claims associated with the JWT. Services use the claims to determine what actions a user is authorized to take. In particular, the \"sub\" (subject) claim uniquely identifies a user inside Tapis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permitted_client.access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also the ttl (time-to-live) claim; Tapis tokens have a finite lifetime, typically a few hours, configurable by tenant. After the token expires, we will need to get a new token in order to continue interacting with Tapis. The Python SDK has convenience methods for managing tokens and even automatically refreshing a token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the system description for our pre-registered S3 bucket:\n",
    "\n",
    "permitted_client.systems.getSystemByName(systemName=storage_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to actually create the storage system -- we will not run here.\n",
    "\n",
    "# the description of an S3 bucket\n",
    "s3_bucket = {\n",
    "  \"name\":storage_id,\n",
    "  \"description\":\"Joe's Bucket\",\n",
    "  \"host\":\"https://tapis-files-test.s3.us-east-1.amazonaws.com/\",\n",
    "  \"systemType\":\"OBJECT_STORE\",\n",
    "  \"defaultAccessMethod\":\"ACCESS_KEY\",\n",
    "  \"effectiveUserId\":\"testuser2\",\n",
    "  \"bucketName\":\"tapis-files-bucket\",\n",
    "  \"rootDir\":\"/\",\n",
    "  \"jobCanExec\": False,\n",
    "  \"transferMethods\":[\"S3\"],\n",
    "  \"accessCredential\":\n",
    "  {\n",
    "    \"accessKey\":\"***\",\n",
    "    \"accessSecret\":\"***\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# create the system in Tapis\n",
    "# permited_client.systems.createSystem(**s3_bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List file of current storage system\n",
    "permitted_client.files.listFiles(systemId=storage_id, path=\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streams API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/streams-api.png \"a title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and Metadata Setup\n",
    "Projects are defined at a top level in the hierarchy of Streams resources. A user registers a project by providing metadata information such as the principal Investigator, project URL, funding resource, etc. A list of authorized users can be added to various project roles to have a controlled access over the project resources. When a project is first registered, a collection is created in the back-end MongoDB. User permissions to access this collection are then set up in the security kernel. Every request to access the project resource or documents within (i.e sites, instruments, variables) goes through a security kernel check and only the authorized user requests are allowed to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Project\n",
    "result, debug = permitted_client.streams.create_project(project_name=project_id,description='project for early adopters demo',\n",
    "                                         owner='testuser2', pi='ajamthe', funding_resource='tapis', project_url='test.tacc.utexas.edu',\n",
    "                                         active=True,_tapis_debug=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/stream-mongo.png \"a title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Site\n",
    "A site is a geographical location that may hold one or more instruments. Sites are next in the streams hierarchy and they inherit permissions from the projects. Project owners can create sites by providing the geographical information such as latitude, longitude and elevation of the site or GeoJSON encoded spatial information. This spatial information is useful when searching sites or data based on location. In the back-end database a site is represented as a JSON document within the project collection. Site permissions are inherited from the project. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Site\n",
    "result, debug = permitted_client.streams.create_site(project_uuid=project_id,site_name=site_id, site_id=site_id,\n",
    "                                      latitude=50, longitude = 10, elevation=2,description='test_site', _tapis_debug=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Instrument\n",
    "Instruments are physical entities that may have one or more embedded sensors to sense various parameters such as temperature, relative humidity, specific conductivity, etc. These sensors referred to as variables in Streams API generate measurements, which are stored in the influxDB along with a ISO8601 timestamp. Instruments are associated with specific sites and projects. Information about the instruments such as site and project ids, name and description of the instrument, etc. are stored in the mongoDB sites JSON document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Instruments\n",
    "result, debug = permitted_client.streams.create_instrument(project_uuid=project_id,topic_category_id ='2',site_id=site_id,\n",
    "                                            inst_name=instrument_id,inst_description='demo instrument',\n",
    "                                            inst_id=instrument_id, _tapis_debug=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Variables\n",
    "Variables are associated with specific instruments. When a variable is created the users provide information such as the name of variable, properties measured, units of measurements, etc. For example, a variable for temperature sensor when created can store measurements in degree Celsius or Fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Variables \n",
    "#Temperature\n",
    "result, debug = permitted_client.streams.create_variable(project_uuid=project_id,topic_category_id ='2',\n",
    "                                          site_id=site_id,inst_id=instrument_id,\n",
    "                                          var_name='temperature', shortname='temp',var_id='temp', _tapis_debug=True)\n",
    "print(result)\n",
    "#Battery Voltage\n",
    "result, debug = permitted_client.streams.create_variable(project_uuid=project_id,topic_category_id ='2',\n",
    "                                          site_id=site_id,inst_id=instrument_id,\n",
    "                                          var_name='battery', shortname='bat', var_id='batv',\n",
    "                                          _tapis_debug=True)\n",
    "print(result)\n",
    "#Specific Conductivity\n",
    "result, debug = permitted_client.streams.create_variable(project_uuid=project_id,topic_category_id ='2',\n",
    "                                          site_id=site_id,inst_id=instrument_id,\n",
    "                                          var_name='specific_conductivity', shortname='spc', var_id='spc',\n",
    "                                          _tapis_debug=True)\n",
    "print(result)\n",
    "#Turbidity\n",
    "result, debug = permitted_client.streams.create_variable(project_uuid=project_id,topic_category_id ='2',\n",
    "                                          site_id=site_id,inst_id=instrument_id,\n",
    "                                          var_name='turbidity', shortname='turb', var_id='turb',\n",
    "                                          _tapis_debug=True)\n",
    "print(result)\n",
    "#PH\n",
    "result, debug = permitted_client.streams.create_variable(project_uuid=project_id,topic_category_id ='2',\n",
    "                                          site_id=site_id,inst_id=instrument_id,\n",
    "                                          var_name='ph_level', shortname='ph', var_id='ph',\n",
    "                                          _tapis_debug=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Permissions\n",
    "Project roles and permissions are stored in the Tapis v3 Security Kernal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Roles\n",
    "permitted_client.sk.getUsersWithRole(user=permitted_username, roleName='streams_user',tenant=tenant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpermitted_client.sk.getUserRoles(user=non_permitted_username,tenant=tenant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpermitted_client.streams.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Site Role  - non-permissioned user\n",
    "result = nonpermitted_client.streams.get_site(project_uuid=project_id, site_id=site_id)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Site Role - permitted user\n",
    "result = permitted_client.streams.get_site(project_uuid=project_id, site_id=site_id)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Measurements\n",
    "Measurements are actual values from the variables, which are stored in the time series database influxDB. Project owners or users can download these measurements by providing a time window of measurement creation and retrieve the data in the CSV or JSON format. This data  can be processed in real time with the help of the Channels API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write Measurements\n",
    "from datetime import datetime\n",
    "import random\n",
    "from random import randint\n",
    "for i in range(0, 10):\n",
    "    datetime_now = datetime.now().isoformat()\n",
    "    result = permitted_client.streams.create_measurement(inst_id=instrument_id,\n",
    "                                          vars=[{\"var_id\": \"temp\", \"value\": randint(85, 89)},\n",
    "                                                {\"var_id\": \"spc\", \"value\": randint(240, 300)},\n",
    "                                                {\"var_id\": \"turb\", \"value\": randint(10, 19)},\n",
    "                                                {\"var_id\": \"ph\", \"value\": randint(1, 10)},\n",
    "                                                {\"var_id\": \"batv\", \"value\": round(random.uniform(10, 13), 2)}],\n",
    "                                          datetime=datetime_now)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Measurements\n",
    "Download the measurements we just created from our instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download measurments as CSV\n",
    "result = permitted_client.streams.list_measurements(inst_id=instrument_id,project_uuid=project_id, site_id=site_id,\n",
    "                                             start_date='2020-05-08T00:00:00Z',end_date='2020-12-30T22:19:25Z',format='csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Measurements to Data Frame\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "input = StringIO(str(result,'utf-8'))\n",
    "df = pd.read_csv(input)\n",
    "df['datetime']=pd.to_datetime(df['time'])\n",
    "df.set_index('datetime',inplace=True)\n",
    "df.pop('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Measurements in the DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "%matplotlib inline\n",
    "xfmt = md.DateFormatter('%H:%M:%S')\n",
    "df.plot(lw=1, colormap='jet', marker='.', \n",
    "        markersize=12, title='Timeseries Stream Output', rot=90).xaxis.set_major_formatter(xfmt)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('test2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an Abaco actor to automatically execute code whenever a sensor registers a temperature reading beyond a predefined temperature threshold, in this case, 90 degrees. The actor is a standalone function that is written in Python and packaged as a Docker container.\n",
    "\n",
    "The code for the actor is available from within the actor directory. When executed, the actor code retrieves all stream data points for the given instrument. It then makes a plot of the data points and uploads the plot to a Tapis S3 bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review actor code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Channel\n",
    "Channels are created using the variable resources. When the data for a specific variable meets a certain condition defined in the channel, an alert or notification is raised. The Channels API leverages Kapacitor to create tasks to process real time streaming data from influxDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Channels require a \"template\" we will use an existing one 'demo_channel_template' that accepts a single condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Channel\n",
    "result,debug =  permitted_client.streams.create_channels(channel_id=channel_id, channel_name='demo.wq.channel', template_id=template_id,\n",
    "                                              triggers_with_actions=[{\"inst_ids\":[\"Ohio_River_Robert_C_Byrd_Locks\"],\n",
    "                                                                      \"condition\":{\"key\":\"Ohio_River_Robert_C_Byrd_Locks.temp\",\"operator\":\">\", \"val\":90}, \n",
    "                                                                      \"action\":{\"method\":\"ACTOR\",\"actor_id\" :actor_id,\n",
    "                                                                                \"message\":\"Instrument: Ohio_River_Robert_C_Byrd_Locks temp exceeded threshold\", \n",
    "                                                                                \"abaco_base_url\":\"https://api.tacc.utexas.edu\",\"nonces\": nonce}}]\n",
    "                                              ,_tapis_debug=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alerts\n",
    "As events are generated an \"Alert\" is created, notifications are sent to the data processing end-points via HTTP POST with details ofthe data raising the alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/alert-abaco.png \"a title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list empty Alerts\n",
    "permitted_client.streams.list_alerts(channel_id=channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger Alert Measurement\n",
    "from datetime import datetime\n",
    "import random\n",
    "from random import randint\n",
    "datetime_now = datetime.now().isoformat()\n",
    "result = permitted_client.streams.create_measurement(inst_id=instrument_id,\n",
    "                                      vars=[{\"var_id\": \"temp\", \"value\": 150},\n",
    "                                            {\"var_id\": \"spc\", \"value\": randint(240, 300)},\n",
    "                                            {\"var_id\": \"turb\", \"value\": randint(10, 19)},\n",
    "                                            {\"var_id\": \"ph\", \"value\": randint(1, 10)},\n",
    "                                            {\"var_id\": \"batv\", \"value\": round(random.uniform(10, 13), 2)}],\n",
    "                                      datetime=datetime_now)\n",
    "print(result)\n",
    "for i in range(0, 5):\n",
    "    datetime_now = datetime.now().isoformat()\n",
    "    result = permitted_client.streams.create_measurement(inst_id=instrument_id,\n",
    "                                          vars=[{\"var_id\": \"temp\", \"value\": randint(85, 89)},\n",
    "                                                {\"var_id\": \"spc\", \"value\": randint(240, 300)},\n",
    "                                                {\"var_id\": \"turb\", \"value\": randint(10, 19)},\n",
    "                                                {\"var_id\": \"ph\", \"value\": randint(1, 10)},\n",
    "                                                {\"var_id\": \"batv\", \"value\": round(random.uniform(10, 13), 2)}],\n",
    "                                          datetime=datetime_now)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list alerts after trigger\n",
    "permitted_client.streams.list_alerts(channel_id=channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "permitted_client.files.listFiles(systemId=storage_id, path=\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angular UI Filebrowser\n",
    "Go to the file browser to preview the generated plot https://tapis-project.github.io/ng-tapis-files-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
